{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from selectolax.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://viblo.asia/announcements/khao-sat-viblo-nhu-cau-phat-trien-su-nghiep-it-toan-cau-PAoJePaA41j\"\n",
    "\n",
    "r = httpx.get(url)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = HTMLParser(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in tree.css('script'):\n",
    "    tag.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract body text\n",
    "content = tree.body.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = re.sub(r'\\s{2,}', ' ', content).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Bài Viết Hỏi Đáp Thảo Luận Thông tin Chưa có thông tin Tất cả thông tin vi Tiếng Việt English Viblo Viblo Code Viblo CTF Viblo CV Viblo Learning Viblo Partner Viblo Battle new Viblo Interview new Đăng nhập/Đăng ký Khảo sát Viblo: Nhu cầu phát triển sự nghiệp IT toàn cầu Bạn đang làm việc trong ngành CNTT và mong muốn phát triển sự nghiệp ở những công ty công nghệ lớn? Hay bạn đang đi học và có nhu cầu đầu quân cho những công ty lớn với mức lương và đãi ngộ khủng sau khi ra trường?Vậy thì chắc chắn, những nội dung mà Viblo chuẩn bị đem đến cho cộng đồng Viblo thời gian tới sẽ là những thứ bạn không thể bỏ lỡ! Chào mừng bạn đến với Khảo sát Viblo: Nhu cầu phát triển sự nghiệp IT toàn cầu! Khảo sát này nhằm tìm hiểu nhu cầu và mong muốn của cộng đồng Viblo về cơ hội định cư và làm việc tại các tập đoàn công nghệ lớn ở trong nước và nước ngoài. Chúng tôi sẽ tìm hiểu về sở thích, kỹ năng hiện tại, và mục tiêu nghề nghiệp, mong muốn phát triển của bạn trong lĩnh vực công nghệ thông tin.Thông tin thu thập được sẽ giúp Viblo cung cấp nội dung, tài nguyên, và hỗ trợ phù hợp nhất cho hành trình phát triển sự nghiệp của bạn.Thời gian thực hiện Khảo sát là: 12 phút. Hãy giúp Viblo chia sẻ ý kiến để mang lại những nội dung chất lượng, hỗ trợ nâng tầm cộng đồng IT Việt Nam trên bản đồ công nghệ toàn cầu!Tham gia khảo sát tại đâyCảm ơn bạn đã dành thời gian quý báu để cung cấp thông tin cho Viblo thông qua khảo sát này.Bắt đầu từ tháng 10, Viblo kết hợp cùng EngineerPro sẽ tổ chức chuỗi seminar liên quan đến lĩnh vực Phỏng vấn và Làm việc tại Big Tech. Chúng mình sẽ dựa vào những thông tin bạn cung cấp để xây dựng nội dung chuỗi seminar gần gũi và thiết thực nhất với người tham dự. Hãy đón chờ những thông tin mới nhất về chuỗi seminar tại Fanpage Viblo và Announcement Viblo nhé!Liên hệNgười dùng có thể liên hệ với Viblo qua những phương thức sau: Gửi tin nhắn trực tiếp tới Fanpage VibloGửi email tới contact@viblo.asiaĐiện thoại: 0888.712.838 (Ms. Linh) (các tình huống khẩn cấp) Mục lục Không có mục lục Announcements 👉 [Viblo CTF: Nhanh Tay Thử Sức Với NEW CTF PUZZLE, Thử Thách Cả Những Hacker Chuyên Nghiệp Nhất] 👈 Viblo team 🌸 [Viblo Khai Bút Đầu Xuân - Tân niên trọn vẹn 2023 | Thể lệ chi tiết] 🌸 Các bước vô cùng đơn giản để rinh quà Tết từ Viblo!! Viblo team cvseesd Viblo team VIBLO ĐỒNG HÀNH CÙNG JAVA SHOW 2022 - CHUỖI SỰ KIỆN DÀNH CHO LẬP TRÌNH VIÊN JAVA Viblo team Viblo Highly Recommends: Rails Girls Hanoi 2017 - Lan tỏa sức mạnh của nữ lập trình viên Viblo team Announcements 👉 [Viblo CTF: Nhanh Tay Thử Sức Với NEW CTF PUZZLE, Thử Thách Cả Những Hacker Chuyên Nghiệp Nhất] 👈 Viblo team 🌸 [Viblo Khai Bút Đầu Xuân - Tân niên trọn vẹn 2023 | Thể lệ chi tiết] 🌸 Các bước vô cùng đơn giản để rinh quà Tết từ Viblo!! Viblo team cvseesd Viblo team VIBLO ĐỒNG HÀNH CÙNG JAVA SHOW 2022 - CHUỖI SỰ KIỆN DÀNH CHO LẬP TRÌNH VIÊN JAVA Viblo team Viblo Highly Recommends: Rails Girls Hanoi 2017 - Lan tỏa sức mạnh của nữ lập trình viên Viblo team Tài nguyên Bài viết Tổ chức Câu hỏi Tags Videos Tác giả Thảo luận Đề xuất hệ thống Công cụ Machine Learning Trạng thái hệ thống Dịch vụ Viblo Viblo Code Viblo CTF Viblo CV Viblo Learning Viblo Partner Viblo Battle Viblo Interview Ứng dụng di động Liên kết © 2024 Viblo. All rights reserved. Về chúng tôi Phản hồi Giúp đỡ FAQs RSS Điều khoản Hãy đăng ký một tài khoản Viblo để nhận được nhiều bài viết thú vị hơn. Đăng nhập Đăng kí '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "\n",
    "# load url to extract information\n",
    "def load_url(url):\n",
    "    r = httpx.get(url)\n",
    "    if (r.status_code == 200):\n",
    "        # Parse the HTML string using selectolax\n",
    "        tree = HTMLParser(r.text)\n",
    "\n",
    "        # After moving them, remove all other unwanted tags like <div>, <script>, etc.\n",
    "        for tag in tree.css('script'):  # Select all tags\n",
    "            tag.decompose()  # Remove the unwanted tags\n",
    "\n",
    "        # Extract the remaining HTML content (with the allowed tags)\n",
    "        content = tree.body.text()\n",
    "        cleaned_html = re.sub(r'\\s{2,}', ' ', content).replace('\\n', '')\n",
    "        return cleaned_html.lower().strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bài viết hỏi đáp thảo luận thông tin chưa có thông tin tất cả thông tin vi tiếng việt english viblo viblo code viblo ctf viblo cv viblo learning viblo partner viblo battle new viblo interview new đăng nhập/đăng ký +7 cỡ chữ 18px độ cao hàng 1.75 mặc định toàn màn hình màu nền đặt lại phuc phan @hoasuathang8 theo dõi 853 43 10 đã đăng vào thg 2 26, 3:26 ch 8 phút đọc 974 1 6 chatgpt series 6: multimodal rag và những phương pháp được nghiên cứu để cải thiện chất lượng hệ thống rag khaibutdauxuan báo cáo thêm vào series của tôi chúc mừng năm mới 2024 đến toàn thể cộng đồng viblo!tiếp tục serries về chatgpt, ở chatgpt series 5 mình có đề cập tới một góc nhìn theo chiều rộng về rag, bạn xem thêm ở đây nhé.bài viết tiếp theo mình sẽ đề cập tới khía cạnh multimodal rag và những phương pháp được nghiên cứu để cải thiện hệ thống rag.multimodal rag trong thực tế thì nhiều tài liệu chứa hỗn hợp các loại nội dung trong đó, có thể bao gồm cả dạng văn bản và ảnh. tuy nhiên, thông được nắm bắt trong hình ảnh sẽ bị mất (bỏ qua) trong hầu hết ứng dụng rag. với sự nổi lên của multimodal llm, chẳng hạn như gpt-4, chúng ta cũng cần xem xét sử dụng kết hợp thông tin hình ảnh trong hệ thống rag. trong framework langchain cũng hỗ trợ việc sử dụng kết hợp hình ảnh. ba cách để sử dụng có thể thử: option 1: sử dụng multimodal embedding (chẳng hạn như clip) để embed ảnh và text.retrieval sử dụng similarity search.đưa ảnh và các đoạn text qua mô hình multimodal llm để tổng hợp câu trả lời. option 2: sử dụng multimodal llm (chẳng hạn như gpt-4, llava, or fuyu-8b) để tạo text tóm tắt từ ảnh.embed và retrieve text.đưa các đoạn text vào mô hình llm để tổng hợp câu trả lời. option 3: sử dụng multimodal llm (chẳng hạn như gpt-4, llava, or fuyu-8b) để tạo text tóm tắt từ ảnh.embed và retrieve các bản tóm tắt ảnh có reference tới raw image. có thể sử dụng multi-vector retriever với vector db chẳng hạn như chroma để lưu trữ raw text và images cùng với bản tóm tắt của chúng để retrieval.đưa raw images và các đoạn text liên quan tới một mô hình multimodal llm để tổng hợp câu trả lời. option 2 phù hợp khi không thể sử dụng multimodal llm để sinh ra câu trả lời do các vấn đề như chi phí, hạ tầng, ... tổng quan về cả 3 options nói trên được mô tả hình dưới đây. nguồn mọi người có thể thử nghiệm qua langchain, họ có cung cấp 1 cookbooks cho option 1 vs option 3.minh họa tổng quan multimodal rag: một số phương pháp nghiên cứu để cải thiện hệ thống rag để nâng cao và cải tiến hệ thống rag, có một số phương pháp mình thấy được refer và sử dụng nhiều trong triển khai thực tế: re-ranking retrieved results: một phương pháp cơ bản và hiệu quả bao gồm việc sử dụng mô hình xếp hạng lại để tinh chỉnh các kết quả thu được thông qua truy xuất ban đầu. cách tiếp cận này ưu tiên các kết quả phù hợp hơn, từ đó cải thiện chất lượng tổng thể của nội dung được tạo ra. monot5, monobert, duobert, v.v. là những ví dụ về các mô hình dl có thể được sử dụng làm re-ranker. để khám phá kỹ về kỹ thuật này, bạn tham khảo hướng dẫn và ví dụ ở đâyflare technique: sau khi reranking, người ta đưa ra thêm phương pháp flare. kỹ thuật này truy vấn động trên internet (cũng có thể là cơ sở tri thức cục bộ) bất cứ khi nào mức độ tin cậy của một phân đoạn nội dung được tạo giảm xuống dưới ngưỡng được chỉ định. điều này khắc phục được hạn chế đáng kể của các hệ thống rag thông thường, vốn thường chỉ truy vấn cơ sở tri thức ngay từ đầu và sau đó tạo ra kết quả cuối cùng. bạn có thể xem thêm cách ứng dụng thực tế của kỹ thuật này ở đây.hyde approach: kỹ thuật hyde giới thiệu một khái niệm đổi mới về việc tạo ra một document giả định để đáp lại một truy vấn. document này sau đó được chuyển đổi thành một embedding vector. điểm độc đáo của phương pháp này nằm ở việc sử dụng vectơ để xác định vùng lân cận tương tự trong corpus không gian embedding, từ đó truy xuất các document thực tương tự dựa trên độ tương tự của vectơ. để tìm hiểu kỹ hơn về phương pháp này, bạn tham khảo hướng dẫn và triển khai code ở đây.chain-of-note: chain-of-noting, được thiết kế để nâng cao độ bền của rag. nền tảng của con là tạo ra một loạt ghi chú đọc cho các tài liệu được truy xuất, cho phép đánh giá toàn diện mức độ liên quan của chúng với truy vấn đầu vào. cách tiếp cận này không chỉ đánh giá mức độ phù hợp của từng tài liệu mà còn xác định chính xác thông tin quan trọng và đáng tin cậy nhất trong đó. quá trình này lọc ra một cách hiệu quả những nội dung không liên quan hoặc kém tin cậy hơn, dẫn đến những phản hồi chính xác hơn và phù hợp với ngữ cảnh hơn. ngoài ra, con còn nâng cao khả năng của rag để xử lý các truy vấn nằm ngoài phạm vi dữ liệu huấn luyện của chúng. trong trường hợp tài liệu được truy xuất không cung cấp bất kỳ thông tin liên quan nào, con có thể hướng dẫn mô hình thừa nhận các hạn chế của nó và phản hồi ở dạng \"unknown\" hoặc đưa ra lời giải thích tốt nhất có thể dựa trên dữ liệu có sẵn, nâng cao độ tin cậy của mô hình. paperself-rag: mô hình self-rag được đào tạo để tạo đầu ra văn bản có nhiều phân đoạn (đoạn là một câu). các phân đoạn này bao gồm cả từ vựng gốc và mã thông báo phản ánh đặc biệt. trong quá trình suy luận, mô hình sẽ quyết định có lấy thêm thông tin hay không. nếu việc truy xuất là không cần thiết, nó sẽ tiến hành giống như một mô hình ngôn ngữ chuẩn. nếu cần truy xuất, mô hình sẽ đánh giá mức độ liên quan của đoạn được truy xuất, độ chính xác của phân đoạn phản hồi và tiện ích tổng thể của phản hồi bằng cách sử dụng mã thông báo phê bình. mô hình có thể xử lý đồng thời nhiều đoạn và sử dụng mã thông báo phản chiếu để được hướng dẫn. paper mỗi phương pháp này cung cấp một cách tiếp cận riêng để tinh chỉnh hệ thống rag, góp phần mang lại kết quả chính xác hơn và phù hợp với ngữ cảnh hơn. để nói sâu về các kỹ thuật trên có thể sẽ cần nhiều hơn, chính vì thế trong nội dung bài viết này chủ yếu mình tập trung vào các keywords để các bạn có thể có 1 số hướng nghiên cứu cho những giải pháp cải thiện cho hệ thống rag trong các ứng dụng thực tế. ai trending chatgpt llm rag all rights reserved báo cáo thêm vào series của tôi mục lục không có mục lục thử thách đề xuất subarray level up!!! thg 11 30, 2023 2:19 ch greedy method dynamic programming greedy method dynamic programming 150 3 1 e play matrix thg 11 30, 2023 7:05 sa matrix matrix 100 2 1 e special substring thg 11 29, 2023 3:54 sa string substring string substring 350 22 16 b câu đố đề xuất 100.times(fn do_rsa end) 200 74 d spongebob spongebob 170 117 d crack it! 200 31 d khóa học đề xuất hệ thống nhúng thg 8 1, 8:40 sa cơ bản 1.5k usergroup 62 1.7k 90 vi xử lý thg 4 9, 4:23 sa cơ bản 4.1k usergroup 173 1.9k 144 ngôn ngữ lập trình r thg 3 8, 8:32 sa cơ bản 5.2k usergroup 154 1.5k 139 tài nguyên bài viết tổ chức câu hỏi tags videos tác giả thảo luận đề xuất hệ thống công cụ machine learning trạng thái hệ thống dịch vụ viblo viblo code viblo ctf viblo cv viblo learning viblo partner viblo battle viblo interview ứng dụng di động liên kết © 2024 viblo. all rights reserved. về chúng tôi phản hồi giúp đỡ faqs rss điều khoản hãy đăng ký một tài khoản viblo để nhận được nhiều bài viết thú vị hơn. đăng nhập đăng kí\n"
     ]
    }
   ],
   "source": [
    "url = \"https://viblo.asia/p/chatgpt-series-6-multimodal-rag-va-nhung-phuong-phap-duoc-nghien-cuu-de-cai-thien-chat-luong-he-thong-rag-aNj4vDKqL6r\"\n",
    "text = load_url(url)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path: str):\n",
    "    \"\"\"\n",
    "    Đọc stopwords từ file và trả về dưới dạng một danh sách.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stopwords = [line.strip() for line in file]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = load_stopwords(\"D:\\\\WorkSpace\\\\PythonWebCrawlData\\\\Demo\\\\backend\\\\stopWord.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str, stopwords: list):\n",
    "    \"\"\"\n",
    "    Xử lý văn bản tiếng Việt: Loại bỏ các ký tự không mong muốn và stopwords dạng từ đơn hoặc cụm từ.\n",
    "    \"\"\"\n",
    "    # Loại bỏ các ký tự đặc biệt nhưng giữ lại dấu tiếng Việt\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Đưa về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # Loại bỏ stopwords\n",
    "    for stopword in stopwords:\n",
    "        # Sử dụng re.sub để loại bỏ stopword (dạng từ hoặc cụm từ) khỏi văn bản\n",
    "        pattern = r'\\b' + re.escape(stopword) + r'\\b'\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Loại bỏ khoảng trắng thừa do việc loại bỏ stopwords\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4410"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanText = clean_text(text, stopword)\n",
    "len(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_tfidf(corpus):\n",
    "    \"\"\"\n",
    "    Tính toán TF-IDF cho một tập các văn bản (corpus) và trả về các từ quan trọng.\n",
    "    \"\"\"\n",
    "    # Khởi tạo vectorizer với giá trị TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Tính toán TF-IDF cho toàn bộ corpus\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Lấy ra các từ tương ứng với các cột trong ma trận TF-IDF\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Trả về ma trận TF-IDF và danh sách các từ\n",
    "    return X, feature_names\n",
    "\n",
    "def filter_important_words(texts, X, feature_names, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Loại bỏ những từ không quan trọng dựa trên giá trị TF-IDF (threshold là ngưỡng để loại bỏ từ).\n",
    "    Trả về văn bản hoàn chỉnh sau khi lọc từ không quan trọng.\n",
    "    \"\"\"\n",
    "    important_texts = []\n",
    "    \n",
    "    for doc_index, text in enumerate(texts):\n",
    "        # Tách từ trong văn bản\n",
    "        words = text.split()\n",
    "\n",
    "        # Lấy ra các giá trị TF-IDF tương ứng của văn bản hiện tại\n",
    "        doc_tfidf = X[doc_index].toarray().flatten()\n",
    "\n",
    "        # Giữ lại những từ có giá trị TF-IDF cao hơn threshold\n",
    "        important_words = [\n",
    "            word for word in words if word in feature_names and doc_tfidf[feature_names.tolist().index(word)] > threshold\n",
    "        ]\n",
    "\n",
    "        # Ghép lại các từ thành văn bản hoàn chỉnh\n",
    "        important_texts.append(\" \".join(important_words))\n",
    "\n",
    "    return important_texts\n",
    "\n",
    "def remove_numbers_and_special_chars(text):\n",
    "    \"\"\"\n",
    "    Hàm loại bỏ số và các ký tự đặc biệt, giữ lại chữ cái có dấu trong văn bản tiếng Việt.\n",
    "    \"\"\"\n",
    "    # Sử dụng regex để loại bỏ số và ký tự đặc biệt nhưng giữ lại dấu tiếng Việt\n",
    "    text = re.sub(r'[0-9]', '', text)  # Loại bỏ số\n",
    "    text = re.sub(r'[^\\w\\sÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơ'\n",
    "                  r'ẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪ'\n",
    "                  r'ỬỮỰỲỴÝỶỸỳỵýỷỹ]', '', text)  # Loại bỏ ký tự đặc biệt nhưng giữ lại dấu tiếng Việt\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Loại bỏ khoảng trắng thừa\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_processing(text, stopword, threshold=0.1):\n",
    "    \n",
    "    # lượt bỏ số và dấu \n",
    "    text = remove_numbers_and_special_chars(text)\n",
    "    \n",
    "    # xử lý văn bản\n",
    "    clean_texts = clean_text(text, stopword)\n",
    "    \n",
    "    # tính toán TF-IDF\n",
    "    cleaned_corpus = [clean_texts for doc in text]\n",
    "    X, feature_names = calculate_tfidf(cleaned_corpus)\n",
    "    \n",
    "    # lọc từ quan trọng\n",
    "    important_texts = filter_important_words(cleaned_corpus, X, feature_names, threshold=threshold)\n",
    "    \n",
    "    return important_texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = pipeline_processing(text, stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thông thông thông viblo viblo viblo viblo viblo viblo viblo viblo độ hình thg multimodal rag phương pháp hệ thống rag thể rag multimodal rag phương pháp hệ thống rag hợp thể ảnh thông hình ảnh rag multimodal llm hạn kết hợp thông hình ảnh hệ thống rag kết hợp hình ảnh thể multimodal hạn ảnh ảnh đoạn mô hình multimodal llm tổng hợp multimodal llm hạn đoạn mô hình llm tổng hợp multimodal llm hạn ảnh thể hạn đoạn mô hình multimodal llm tổng hợp thể multimodal llm tổng mô hình thể tổng multimodal rag phương pháp hệ thống rag hệ thống rag phương pháp phương pháp mô hình kết thông truy xuất kết tổng thể mô hình thể kỹ kỹ phương pháp kỹ truy thể độ đoạn hạn hệ thống rag thông truy kết thể kỹ kỹ truy phương pháp truy xuất độ kỹ phương pháp độ rag truy xuất độ truy độ thông phản rag truy hợp truy xuất thông thể mô hình hạn phản thể độ mô hình mô hình đoạn đoạn đoạn thông phản mô hình thông truy xuất mô hình truy xuất mô hình độ đoạn truy xuất độ đoạn phản tổng thể phản thông mô hình thể đoạn thông phản phương pháp hệ thống rag kết kỹ thể thể pháp hệ thống rag llm rag xuất thg thg thg xuất xuất hệ thống thg thg thg xuất hệ thống hệ thống viblo viblo viblo viblo viblo viblo viblo viblo kết viblo phản viblo'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đoạn chương trình hoàn chỉnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "\n",
    "# load url to extract information\n",
    "import re\n",
    "import asyncio\n",
    "\n",
    "async def load_url(url):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.get(url)\n",
    "        if r.status_code == 200:\n",
    "            tree = HTMLParser(r.text)\n",
    "\n",
    "            # Loại bỏ các thẻ không mong muốn\n",
    "            for tag in tree.css('script'):\n",
    "                tag.decompose()\n",
    "\n",
    "            content = tree.body.text()\n",
    "            cleaned_html = re.sub(r'\\s{2,}', ' ', content).replace('\\n', '')\n",
    "            return cleaned_html.lower().strip()\n",
    "    return None\n",
    "\n",
    "def load_stopwords(file_path: str):\n",
    "    \"\"\"\n",
    "    Đọc stopwords từ file và trả về dưới dạng một danh sách.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stopwords = [line.strip() for line in file]\n",
    "    return stopwords\n",
    "\n",
    "def clean_text(text: str, stopwords: list):\n",
    "    \"\"\"\n",
    "    Xử lý văn bản tiếng Việt: Loại bỏ các ký tự không mong muốn và stopwords dạng từ đơn hoặc cụm từ.\n",
    "    \"\"\"\n",
    "    # Loại bỏ các ký tự đặc biệt nhưng giữ lại dấu tiếng Việt\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Đưa về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # Loại bỏ stopwords\n",
    "    for stopword in stopwords:\n",
    "        # Sử dụng re.sub để loại bỏ stopword (dạng từ hoặc cụm từ) khỏi văn bản\n",
    "        pattern = r'\\b' + re.escape(stopword) + r'\\b'\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Loại bỏ khoảng trắng thừa do việc loại bỏ stopwords\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bài viết hỏi đáp thảo luận thông tin chưa có thông tin tất cả thông tin vi tiếng việt english viblo viblo code viblo ctf viblo cv viblo learning viblo partner viblo battle new viblo interview new đăng nhập/đăng ký +7 cỡ chữ 18px độ cao hàng 1.75 mặc định toàn màn hình màu nền đặt lại phuc phan @hoasuathang8 theo dõi 853 43 10 đã đăng vào thg 2 26, 3:26 ch 8 phút đọc 974 1 6 chatgpt series 6: multimodal rag và những phương pháp được nghiên cứu để cải thiện chất lượng hệ thống rag khaibutdauxuan báo cáo thêm vào series của tôi chúc mừng năm mới 2024 đến toàn thể cộng đồng viblo!tiếp tục serries về chatgpt, ở chatgpt series 5 mình có đề cập tới một góc nhìn theo chiều rộng về rag, bạn xem thêm ở đây nhé.bài viết tiếp theo mình sẽ đề cập tới khía cạnh multimodal rag và những phương pháp được nghiên cứu để cải thiện hệ thống rag.multimodal rag trong thực tế thì nhiều tài liệu chứa hỗn hợp các loại nội dung trong đó, có thể bao gồm cả dạng văn bản và ảnh. tuy nhiên, thông được nắm bắt trong hình ảnh sẽ bị mất (bỏ qua) trong hầu hết ứng dụng rag. với sự nổi lên của multimodal llm, chẳng hạn như gpt-4, chúng ta cũng cần xem xét sử dụng kết hợp thông tin hình ảnh trong hệ thống rag. trong framework langchain cũng hỗ trợ việc sử dụng kết hợp hình ảnh. ba cách để sử dụng có thể thử: option 1: sử dụng multimodal embedding (chẳng hạn như clip) để embed ảnh và text.retrieval sử dụng similarity search.đưa ảnh và các đoạn text qua mô hình multimodal llm để tổng hợp câu trả lời. option 2: sử dụng multimodal llm (chẳng hạn như gpt-4, llava, or fuyu-8b) để tạo text tóm tắt từ ảnh.embed và retrieve text.đưa các đoạn text vào mô hình llm để tổng hợp câu trả lời. option 3: sử dụng multimodal llm (chẳng hạn như gpt-4, llava, or fuyu-8b) để tạo text tóm tắt từ ảnh.embed và retrieve các bản tóm tắt ảnh có reference tới raw image. có thể sử dụng multi-vector retriever với vector db chẳng hạn như chroma để lưu trữ raw text và images cùng với bản tóm tắt của chúng để retrieval.đưa raw images và các đoạn text liên quan tới một mô hình multimodal llm để tổng hợp câu trả lời. option 2 phù hợp khi không thể sử dụng multimodal llm để sinh ra câu trả lời do các vấn đề như chi phí, hạ tầng, ... tổng quan về cả 3 options nói trên được mô tả hình dưới đây. nguồn mọi người có thể thử nghiệm qua langchain, họ có cung cấp 1 cookbooks cho option 1 vs option 3.minh họa tổng quan multimodal rag: một số phương pháp nghiên cứu để cải thiện hệ thống rag để nâng cao và cải tiến hệ thống rag, có một số phương pháp mình thấy được refer và sử dụng nhiều trong triển khai thực tế: re-ranking retrieved results: một phương pháp cơ bản và hiệu quả bao gồm việc sử dụng mô hình xếp hạng lại để tinh chỉnh các kết quả thu được thông qua truy xuất ban đầu. cách tiếp cận này ưu tiên các kết quả phù hợp hơn, từ đó cải thiện chất lượng tổng thể của nội dung được tạo ra. monot5, monobert, duobert, v.v. là những ví dụ về các mô hình dl có thể được sử dụng làm re-ranker. để khám phá kỹ về kỹ thuật này, bạn tham khảo hướng dẫn và ví dụ ở đâyflare technique: sau khi reranking, người ta đưa ra thêm phương pháp flare. kỹ thuật này truy vấn động trên internet (cũng có thể là cơ sở tri thức cục bộ) bất cứ khi nào mức độ tin cậy của một phân đoạn nội dung được tạo giảm xuống dưới ngưỡng được chỉ định. điều này khắc phục được hạn chế đáng kể của các hệ thống rag thông thường, vốn thường chỉ truy vấn cơ sở tri thức ngay từ đầu và sau đó tạo ra kết quả cuối cùng. bạn có thể xem thêm cách ứng dụng thực tế của kỹ thuật này ở đây.hyde approach: kỹ thuật hyde giới thiệu một khái niệm đổi mới về việc tạo ra một document giả định để đáp lại một truy vấn. document này sau đó được chuyển đổi thành một embedding vector. điểm độc đáo của phương pháp này nằm ở việc sử dụng vectơ để xác định vùng lân cận tương tự trong corpus không gian embedding, từ đó truy xuất các document thực tương tự dựa trên độ tương tự của vectơ. để tìm hiểu kỹ hơn về phương pháp này, bạn tham khảo hướng dẫn và triển khai code ở đây.chain-of-note: chain-of-noting, được thiết kế để nâng cao độ bền của rag. nền tảng của con là tạo ra một loạt ghi chú đọc cho các tài liệu được truy xuất, cho phép đánh giá toàn diện mức độ liên quan của chúng với truy vấn đầu vào. cách tiếp cận này không chỉ đánh giá mức độ phù hợp của từng tài liệu mà còn xác định chính xác thông tin quan trọng và đáng tin cậy nhất trong đó. quá trình này lọc ra một cách hiệu quả những nội dung không liên quan hoặc kém tin cậy hơn, dẫn đến những phản hồi chính xác hơn và phù hợp với ngữ cảnh hơn. ngoài ra, con còn nâng cao khả năng của rag để xử lý các truy vấn nằm ngoài phạm vi dữ liệu huấn luyện của chúng. trong trường hợp tài liệu được truy xuất không cung cấp bất kỳ thông tin liên quan nào, con có thể hướng dẫn mô hình thừa nhận các hạn chế của nó và phản hồi ở dạng \"unknown\" hoặc đưa ra lời giải thích tốt nhất có thể dựa trên dữ liệu có sẵn, nâng cao độ tin cậy của mô hình. paperself-rag: mô hình self-rag được đào tạo để tạo đầu ra văn bản có nhiều phân đoạn (đoạn là một câu). các phân đoạn này bao gồm cả từ vựng gốc và mã thông báo phản ánh đặc biệt. trong quá trình suy luận, mô hình sẽ quyết định có lấy thêm thông tin hay không. nếu việc truy xuất là không cần thiết, nó sẽ tiến hành giống như một mô hình ngôn ngữ chuẩn. nếu cần truy xuất, mô hình sẽ đánh giá mức độ liên quan của đoạn được truy xuất, độ chính xác của phân đoạn phản hồi và tiện ích tổng thể của phản hồi bằng cách sử dụng mã thông báo phê bình. mô hình có thể xử lý đồng thời nhiều đoạn và sử dụng mã thông báo phản chiếu để được hướng dẫn. paper mỗi phương pháp này cung cấp một cách tiếp cận riêng để tinh chỉnh hệ thống rag, góp phần mang lại kết quả chính xác hơn và phù hợp với ngữ cảnh hơn. để nói sâu về các kỹ thuật trên có thể sẽ cần nhiều hơn, chính vì thế trong nội dung bài viết này chủ yếu mình tập trung vào các keywords để các bạn có thể có 1 số hướng nghiên cứu cho những giải pháp cải thiện cho hệ thống rag trong các ứng dụng thực tế. ai trending chatgpt llm rag all rights reserved báo cáo thêm vào series của tôi mục lục không có mục lục thử thách đề xuất subarray level up!!! thg 11 30, 2023 2:19 ch greedy method dynamic programming greedy method dynamic programming 150 3 1 e play matrix thg 11 30, 2023 7:05 sa matrix matrix 100 2 1 e special substring thg 11 29, 2023 3:54 sa string substring string substring 350 22 16 b câu đố đề xuất 100.times(fn do_rsa end) 200 74 d spongebob spongebob 170 117 d crack it! 200 31 d khóa học đề xuất hệ thống nhúng thg 8 1, 8:40 sa cơ bản 1.5k usergroup 62 1.7k 90 vi xử lý thg 4 9, 4:23 sa cơ bản 4.1k usergroup 173 1.9k 144 ngôn ngữ lập trình r thg 3 8, 8:32 sa cơ bản 5.2k usergroup 154 1.5k 139 tài nguyên bài viết tổ chức câu hỏi tags videos tác giả thảo luận đề xuất hệ thống công cụ machine learning trạng thái hệ thống dịch vụ viblo viblo code viblo ctf viblo cv viblo learning viblo partner viblo battle viblo interview ứng dụng di động liên kết © 2024 viblo. all rights reserved. về chúng tôi phản hồi giúp đỡ faqs rss điều khoản hãy đăng ký một tài khoản viblo để nhận được nhiều bài viết thú vị hơn. đăng nhập đăng kí\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4410"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "url = \"https://viblo.asia/p/chatgpt-series-6-multimodal-rag-va-nhung-phuong-phap-duoc-nghien-cuu-de-cai-thien-chat-luong-he-thong-rag-aNj4vDKqL6r\"\n",
    "\n",
    "\n",
    "stopword = load_stopwords(\"D:\\\\WorkSpace\\\\PythonWebCrawlData\\\\Demo\\\\backend\\\\stopWord.txt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = asyncio.run(load_url(url))\n",
    "# print(text)\n",
    "\n",
    "# cleanText = clean_text(text, stopword)\n",
    "# len(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 332 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleanText = clean_text(cleanText, stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
